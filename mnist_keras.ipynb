{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "The available CPU/GPU devices on your system\n",
      "====================================================================================================\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1059698111660476798\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2187788288\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 11686142320101627393\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the environment variables\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Double check that you have the correct devices visible to TF\n",
    "print(\"{0}\\nThe available CPU/GPU devices on your system\\n{0}\".format('=' * 100))\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import input_data\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from copy import deepcopy\n",
    "#from imageset import ImageSet\n",
    "K.set_image_dim_ordering('th')\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "zfac = 0.0\n",
    "epochs = 51\n",
    "components_g = 30\n",
    "iterations_g = 5\n",
    "keep_g = False\n",
    "samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from copy import deepcopy\n",
    "\n",
    "epsilon = 0.001\n",
    "\n",
    "class ImageSet():\n",
    "    \"\"\" This a set of images. A method can dirty them up.\n",
    "        A method can recover them from a pca model\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.X_project = np.copy(X)\n",
    "#        self.X_project = None\n",
    "        self.y = y\n",
    "        self.mean = None\n",
    "        self.pca = None\n",
    "        self.image_mask = []\n",
    "        \n",
    "#    @classmethod\n",
    "    def dirty(self, zerofac):\n",
    "        \"\"\" This method dirty's the images up by a factor of zerofac.\n",
    "            If zerofac is 1 the entire image is set to zero. If it is\n",
    "            0 the image is not changed at all.\"\"\"\n",
    "        points = np.shape(self.X)[1]\n",
    "        for iimage in range(np.shape(self.X)[0]):\n",
    "            raw_mask = np.random.ranf(points) + (0.5 - zerofac)\n",
    "            mask = np.rint(raw_mask)\n",
    "            self.X[iimage] = self.X[iimage] * mask\n",
    "            \"\"\" This last modification is a tweak to note where points were set\n",
    "                to zero for future recovery\"\"\"\n",
    "            self.X[iimage] = self.X[iimage] + epsilon*(mask-1.0)\n",
    "            image_mask = self.X[iimage] > -epsilon/2.0\n",
    "            self.image_mask.append(image_mask)\n",
    "        self.X_project = np.copy(self.X)\n",
    "        \n",
    "    def pca_calc(self, components):\n",
    "        \"\"\" This method calculates the pca model using the using the\n",
    "            the images in this Image_set \"\"\"\n",
    "\n",
    "        self.pca = PCA(n_components=components)\n",
    "        self.pca.fit(self.X_project)\n",
    "        \n",
    "    def mean_calc(self):\n",
    "        \"\"\" This method calculates the mean of the images over all images.\n",
    "            It only calculates over the clean images so masks must be \n",
    "            calculated for each image.\"\"\"\n",
    "            \n",
    "        image_count = np.zeros(np.shape(self.X)[1])\n",
    "        image_sum = np.zeros(np.shape(self.X)[1])\n",
    "        \n",
    "        for iimage in range(np.shape(self.X)[0]):\n",
    "            image = self.X[iimage]\n",
    "#            image_mask_good = image > -0.00001\n",
    "            image_mask = self.image_mask[iimage]\n",
    "            image_count[image_mask] += 1\n",
    "            image_sum[image_mask] += image[image_mask]\n",
    "            \n",
    "        self.mean = image_sum/image_count\n",
    "        \n",
    "    def recover_from_pca(self, pca, keep_orig = False):\n",
    "        \"\"\" This method recovers images from a passed pca object.\n",
    "            It puts the recovered image in X_project.\n",
    "            keep_orig means to keep values at original points if\n",
    "            true. If False overwrite with values from pca projection\"\"\"\n",
    "#        for iimage in range(np.shape(self.X)[0]):\n",
    "        for iimage in range(np.shape(self.X)[0]):\n",
    "#            if (iimage % 10000 == 0):\n",
    "#                print(iimage)\n",
    "            image = self.X[iimage]\n",
    "            image_prime = image - pca.mean_\n",
    "#            image_mask_indicies = image < 0.0\n",
    "            image_mask = np.invert(self.image_mask[iimage])\n",
    "            eigen_vec = deepcopy(pca.components_)\n",
    "            for i in range(pca.n_components_):\n",
    "                eigen_vec[i][image_mask] = 0.0\n",
    "            eigen_vec_transpose = eigen_vec.transpose()\n",
    "            A = eigen_vec.dot(eigen_vec_transpose)\n",
    "            b = np.zeros(pca.n_components_)\n",
    "            for i in range(pca.n_components_):\n",
    "                b[i] = image_prime.dot(eigen_vec[i])\n",
    "            coeff = np.linalg.solve(A,b)\n",
    "            image = np.zeros(np.shape(self.X)[1])\n",
    "            \n",
    "            for i in range(pca.n_components_):\n",
    "                image += coeff[i] * pca.components_[i]\n",
    "            image += pca.mean_\n",
    "            \n",
    "            if keep_orig:\n",
    "                image[~image_mask] = self.X[iimage][~image_mask]\n",
    "            \n",
    "            self.X_project[iimage] = image\n",
    "            \n",
    "    def recover_from_pca_mean(self,pca):\n",
    "        \"\"\" This method replaces missing values with values from the mean computed\n",
    "           from a principle component analysis of clean images\"\"\"\n",
    "           \n",
    "        \n",
    "        for iimage in range(np.shape(self.X)[0]):\n",
    "            \n",
    "            image = np.copy(self.X[iimage])\n",
    "#            image_mask_indicies = image < 0.0\n",
    "            image_mask = np.invert(self.image_mask[iimage])\n",
    "            image[image_mask] = pca.mean_[image_mask]\n",
    "            \n",
    "            self.X_project[iimage] = image\n",
    "            \n",
    "    def recover_from_self_mean(self):\n",
    "        \" This method replaces missing values with values from own mean\"\"\"\n",
    "#        image = np.zeros(np.shape(self.X)[1])\n",
    "        \n",
    "        for iimage in range(np.shape(self.X)[0]):\n",
    "            image = np.copy(self.X[iimage])\n",
    "#            image_mask_indicies = image < 0.0\n",
    "            image_mask = np.invert(self.image_mask[iimage])\n",
    "            image[image_mask] = self.mean[image_mask]\n",
    "            self.X_project[iimage] = image\n",
    "            \n",
    "            \n",
    "    def recover_from_self_pca(self, components, iterations, keep_orig = False):\n",
    "        \"\"\" This method recovers images from it's own image set using\n",
    "            iterative pca technique described in Everson and Sirovich\"\"\"\n",
    "            \n",
    "        \"\"\"np.save(\"self_pca_X_b\", self.X[0])\n",
    "        np.save(\"self_pca_X_project_b\", self.X_project[0])\"\"\"\n",
    "        self.recover_from_self_mean()\n",
    "        \n",
    "        \n",
    "        for _ in range(iterations-1):\n",
    "            print(\"doing iteration\")\n",
    "            self.pca_calc(components = components)\n",
    "            self.recover_from_pca(self.pca, keep_orig=False)\n",
    "#            sys.exit(\"Error message\")\n",
    "\n",
    "        self.pca_calc(components = components)\n",
    "        self.recover_from_pca(self.pca, keep_orig=keep_orig)  \n",
    "        \n",
    "        \"\"\"np.save(\"self_pca_X_a\", self.X[0])\n",
    "        np.save(\"self_pca_X_project_a\", self.X_project[0])\n",
    "        sys.exit()\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "     \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_example(restore = None, zerofac = 0.0, model = None, components = 0, \n",
    "                keep = False, iterations = 3):\n",
    "    \"\"\" The run_example runs one example and returns the error. \n",
    "        The main program then does statistics on the errors\"\"\"\n",
    "        \n",
    "\n",
    "    data = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    X_train_d, y_train_d = data.train.next_batch(50000)\n",
    "    X_test_d, y_test_d = data.test.next_batch(11000)\n",
    "    np.save(\"out_train_X\", X_train_d)\n",
    "    np.save(\"out_train_y\", y_train_d)\n",
    "    np.save(\"out_test_X\", X_test_d)\n",
    "    np.save(\"out_test_y\", y_test_d) \n",
    "\n",
    "    \"\"\"X_train_d = np.load(\"out_train_X.npy\")\n",
    "    y_train_d = np.load(\"out_train_y.npy\")\n",
    "    X_test_d = np.load(\"out_test_X.npy\")\n",
    "    y_test_d = np.load(\"out_test_y.npy\")\"\"\"\n",
    "\n",
    "    N_clean = 5000\n",
    "    N_images = X_train_d.shape[0]\n",
    "\n",
    "\n",
    "    clean_images = ImageSet(np.copy(X_train_d[0:N_clean]), np.copy(y_train_d[0:N_clean]))\n",
    "    clean_images.pca_calc(components)\n",
    "    \n",
    "#    train_X = np.copy(X_train_d[N_clean:N_images])\n",
    "#    train_y = np.copy(y_train_d[N_clean:N_images])\n",
    "#    dirty_train = ImageSet(train_X, train_y)\n",
    "\n",
    "    dirty_train = ImageSet(np.copy(X_train_d[N_clean:N_images]), np.copy(y_train_d[N_clean:N_images]))\n",
    "    dirty_test = ImageSet(np.copy(X_test_d), np.copy(y_test_d))\n",
    "    \n",
    "#    dirty_train = ImageSet(X_train_d[N_clean:N_images], y_train_d[N_clean:N_images])\n",
    "#    dirty_test = ImageSet(X_test_d, y_test_d)\n",
    "\n",
    "    \n",
    "    if restore == None:\n",
    "        pass\n",
    "    else:\n",
    "        dirty_train.dirty(zerofac)\n",
    "        dirty_train.mean_calc()\n",
    "        dirty_test.dirty(zerofac)\n",
    "        dirty_test.mean_calc()\n",
    "    if restore == 'pca_mean':\n",
    "        dirty_train.recover_from_pca_mean(clean_images.pca)\n",
    "        dirty_test.recover_from_pca_mean(clean_images.pca)\n",
    "    elif restore == 'self_mean':\n",
    "        dirty_train.recover_from_self_mean()\n",
    "        dirty_test.recover_from_self_mean()\n",
    "    elif restore == 'pca':\n",
    "        with tf.device('/cpu:0'):\n",
    "            dirty_train.recover_from_pca(clean_images.pca, keep_orig=keep)\n",
    "            dirty_test.recover_from_pca(clean_images.pca, keep_orig=keep)\n",
    "    elif restore == 'self_pca':\n",
    "        with tf.device('/cpu:0'): \n",
    "            dirty_train.recover_from_self_pca(components = components, iterations=iterations, keep_orig=True)\n",
    "            dirty_train.pca_calc(components)\n",
    "            dirty_test.mean_calc()\n",
    "            dirty_train.pca.mean_ = dirty_test.mean\n",
    "            dirty_test.recover_from_pca(dirty_train.pca, keep_orig=True)\n",
    "    elif restore == 'compress':\n",
    "        with tf.device('/cpu:0'):\n",
    "            pca = PCA(n_components=components)\n",
    "            pca.fit(clean_images.X)\n",
    "            coeffs = pca.transform(dirty_train.X_project)\n",
    "            dirty_train.X_project = pca.inverse_transform(coeffs)\n",
    "            coeffs = pca.transform(dirty_test.X_project)\n",
    "            dirty_test.X_project = pca.inverse_transform(coeffs)\n",
    "            diff = np.sum(np.absolute(dirty_train.X - dirty_train.X_project))\n",
    "            mag = np.sum(np.absolute(dirty_train.X))\n",
    "            print(\"difference is \", diff, mag, \"with components\", components)\n",
    "\n",
    "    X_dirty_train = dirty_train.X_project\n",
    "    X_dirty_test = dirty_test.X_project\n",
    "\n",
    "    X_train = X_dirty_train.reshape(X_dirty_train.shape[0], 1, 28, 28).astype('float32')\n",
    "    X_test = X_dirty_test.reshape(X_dirty_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "    X_train = X_train / 255\n",
    "    X_test = X_test / 255\n",
    "\n",
    "    y_train = dirty_train.y\n",
    "    y_test = dirty_test.y\n",
    "\n",
    "# build the model\n",
    "    model = larger_model()\n",
    "# Fit the model\n",
    "    with tf.device('/gpu:0'):\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=100, verbose=0)\n",
    "# Final evaluation of the model\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "    \n",
    "    if K.backend() == 'tensorflow':\n",
    "        K.clear_session()\n",
    "    del dirty_train\n",
    "    del dirty_test\n",
    "    del clean_images\n",
    "    \n",
    "    return (100-scores[1]*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('doing clean on sample ', 0)\n",
      "('doing clean on sample ', 1)\n",
      "('doing clean on sample ', 2)\n",
      "('doing clean on sample ', 3)\n",
      "('doing clean on sample ', 4)\n",
      "('doing clean on sample ', 5)\n",
      "('doing clean on sample ', 6)\n",
      "('doing clean on sample ', 7)\n",
      "('doing clean on sample ', 8)\n",
      "('doing clean on sample ', 9)\n",
      "('doing pca_mean on sample ', 0)\n",
      "('doing pca_mean on sample ', 1)\n",
      "('doing pca_mean on sample ', 2)\n",
      "('doing pca_mean on sample ', 3)\n",
      "('doing pca_mean on sample ', 4)\n",
      "('doing pca_mean on sample ', 5)\n",
      "('doing pca_mean on sample ', 6)\n",
      "('doing pca_mean on sample ', 7)\n",
      "('doing pca_mean on sample ', 8)\n",
      "('doing pca_mean on sample ', 9)\n",
      "('the mean for pca_mean is %5.3f with standard deviation of %5.3f', (100.0, 0.0))\n",
      "('doing self_mean on sample ', 0)\n",
      "('doing self_mean on sample ', 1)\n",
      "('doing self_mean on sample ', 2)\n",
      "('doing self_mean on sample ', 3)\n",
      "('doing self_mean on sample ', 4)\n",
      "('doing self_mean on sample ', 5)\n",
      "('doing self_mean on sample ', 6)\n",
      "('doing self_mean on sample ', 7)\n",
      "('doing self_mean on sample ', 8)\n",
      "('doing self_mean on sample ', 9)\n",
      "('the mean for self_mean is %5.3f with standard deviation of %5.3f', (100.0, 0.0))\n",
      "('doing pca on sample ', 0)\n",
      "('doing pca on sample ', 1)\n",
      "('doing pca on sample ', 2)\n",
      "('doing pca on sample ', 3)\n",
      "('doing pca on sample ', 4)\n",
      "('doing pca on sample ', 5)\n",
      "('doing pca on sample ', 6)\n",
      "('doing pca on sample ', 7)\n",
      "('doing pca on sample ', 8)\n",
      "('doing pca on sample ', 9)\n",
      "('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (True, 100, 100.0, 0.0))\n",
      "('doing self_pca on sample ', 0)\n",
      "('doing self_pca on sample ', 1)\n",
      "('doing self_pca on sample ', 2)\n",
      "('doing self_pca on sample ', 3)\n",
      "('doing self_pca on sample ', 4)\n",
      "('doing self_pca on sample ', 5)\n",
      "('doing self_pca on sample ', 6)\n",
      "('doing self_pca on sample ', 7)\n",
      "('doing self_pca on sample ', 8)\n",
      "('doing self_pca on sample ', 9)\n",
      "('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (True, 100, 100.0, 0.0))\n",
      "('doing self_pca on sample ', 0)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 1497062.2, 4613556.5, 'with components', 100)\n",
      "Large CNN Error: 1.29%\n",
      "('doing self_pca on sample ', 1)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 1492565.8, 4610400.0, 'with components', 100)\n",
      "Large CNN Error: 1.34%\n",
      "('doing self_pca on sample ', 2)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 1498540.1, 4606323.0, 'with components', 100)\n",
      "Large CNN Error: 1.42%\n",
      "('doing self_pca on sample ', 3)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 1494229.0, 4613074.0, 'with components', 100)\n",
      "Large CNN Error: 1.37%\n",
      "('doing self_pca on sample ', 4)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 1493220.0, 4610777.0, 'with components', 100)\n",
      "Large CNN Error: 1.43%\n",
      "('doing self_pca on sample ', 5)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 1492142.6, 4611962.5, 'with components', 100)\n",
      "Large CNN Error: 1.52%\n",
      "('doing self_pca on sample ', 6)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 1495488.6, 4610359.5, 'with components', 100)\n",
      "Large CNN Error: 1.38%\n",
      "('doing self_pca on sample ', 7)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 1495551.4, 4613865.5, 'with components', 100)\n",
      "Large CNN Error: 1.40%\n",
      "('doing self_pca on sample ', 8)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 1494151.9, 4612958.5, 'with components', 100)\n",
      "Large CNN Error: 1.45%\n",
      "('doing self_pca on sample ', 9)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 1491206.0, 4609872.0, 'with components', 100)\n",
      "Large CNN Error: 1.40%\n",
      "('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (True, 100, 1.4000000000000028, 0.05919571006024103))\n",
      "('doing self_pca on sample ', 0)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 957211.25, 4609313.0, 'with components', 200)\n",
      "Large CNN Error: 1.34%\n",
      "('doing self_pca on sample ', 1)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 954919.75, 4616959.5, 'with components', 200)\n",
      "Large CNN Error: 1.40%\n",
      "('doing self_pca on sample ', 2)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 958040.5, 4609839.5, 'with components', 200)\n",
      "Large CNN Error: 1.38%\n",
      "('doing self_pca on sample ', 3)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 953074.2, 4607265.5, 'with components', 200)\n",
      "Large CNN Error: 1.44%\n",
      "('doing self_pca on sample ', 4)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 956017.75, 4607965.5, 'with components', 200)\n",
      "Large CNN Error: 1.33%\n",
      "('doing self_pca on sample ', 5)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 955065.25, 4608850.0, 'with components', 200)\n",
      "Large CNN Error: 1.32%\n",
      "('doing self_pca on sample ', 6)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 952656.44, 4607127.5, 'with components', 200)\n",
      "Large CNN Error: 1.33%\n",
      "('doing self_pca on sample ', 7)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 952455.1, 4607707.5, 'with components', 200)\n",
      "Large CNN Error: 1.22%\n",
      "('doing self_pca on sample ', 8)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 959248.0, 4615364.5, 'with components', 200)\n",
      "Large CNN Error: 1.32%\n",
      "('doing self_pca on sample ', 9)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('difference is ', 957865.8, 4613154.5, 'with components', 200)\n",
      "Large CNN Error: 1.38%\n",
      "('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (True, 200, 1.3445454549789446, 0.056838178237022016))\n",
      "('doing self_pca on sample ', 0)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 616227.8, 4613081.0, 'with components', 300)\n",
      "Large CNN Error: 1.47%\n",
      "('doing self_pca on sample ', 1)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 613612.1, 4604251.0, 'with components', 300)\n",
      "Large CNN Error: 1.46%\n",
      "('doing self_pca on sample ', 2)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 612281.9, 4612815.0, 'with components', 300)\n",
      "Large CNN Error: 1.23%\n",
      "('doing self_pca on sample ', 3)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 616107.2, 4611366.5, 'with components', 300)\n",
      "Large CNN Error: 1.55%\n",
      "('doing self_pca on sample ', 4)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 615535.2, 4610711.5, 'with components', 300)\n",
      "Large CNN Error: 1.32%\n",
      "('doing self_pca on sample ', 5)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 612089.5, 4607661.0, 'with components', 300)\n",
      "Large CNN Error: 1.43%\n",
      "('doing self_pca on sample ', 6)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 616767.6, 4607790.0, 'with components', 300)\n",
      "Large CNN Error: 1.30%\n",
      "('doing self_pca on sample ', 7)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 616940.9, 4613229.0, 'with components', 300)\n",
      "Large CNN Error: 1.44%\n",
      "('doing self_pca on sample ', 8)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 615248.75, 4613249.5, 'with components', 300)\n",
      "Large CNN Error: 1.45%\n",
      "('doing self_pca on sample ', 9)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 615839.9, 4613172.0, 'with components', 300)\n",
      "Large CNN Error: 1.41%\n",
      "('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (True, 300, 1.404545455412432, 0.09001836377456784))\n",
      "('doing self_pca on sample ', 0)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 271825.88, 4604515.5, 'with components', 400)\n",
      "Large CNN Error: 1.47%\n",
      "('doing self_pca on sample ', 1)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 269662.12, 4610046.5, 'with components', 400)\n",
      "Large CNN Error: 1.44%\n",
      "('doing self_pca on sample ', 2)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 279322.88, 4609934.0, 'with components', 400)\n",
      "Large CNN Error: 1.27%\n",
      "('doing self_pca on sample ', 3)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 274559.75, 4612866.0, 'with components', 400)\n",
      "Large CNN Error: 1.35%\n",
      "('doing self_pca on sample ', 4)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 275639.2, 4611731.5, 'with components', 400)\n",
      "Large CNN Error: 1.39%\n",
      "('doing self_pca on sample ', 5)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 274394.75, 4610556.0, 'with components', 400)\n",
      "Large CNN Error: 1.40%\n",
      "('doing self_pca on sample ', 6)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 275876.72, 4612448.5, 'with components', 400)\n",
      "Large CNN Error: 1.29%\n",
      "('doing self_pca on sample ', 7)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 274249.38, 4620460.0, 'with components', 400)\n",
      "Large CNN Error: 1.45%\n",
      "('doing self_pca on sample ', 8)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 271230.97, 4608669.5, 'with components', 400)\n",
      "Large CNN Error: 1.27%\n",
      "('doing self_pca on sample ', 9)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 267094.1, 4607757.0, 'with components', 400)\n",
      "Large CNN Error: 1.35%\n",
      "('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (True, 400, 1.3690909095243966, 0.07032392546947347))\n",
      "('doing self_pca on sample ', 0)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 72117.87, 4612596.5, 'with components', 500)\n",
      "Large CNN Error: 1.42%\n",
      "('doing self_pca on sample ', 1)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 76041.21, 4605067.5, 'with components', 500)\n",
      "Large CNN Error: 1.38%\n",
      "('doing self_pca on sample ', 2)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 73449.02, 4613648.5, 'with components', 500)\n",
      "Large CNN Error: 1.30%\n",
      "('doing self_pca on sample ', 3)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 73238.305, 4617953.5, 'with components', 500)\n",
      "Large CNN Error: 1.43%\n",
      "('doing self_pca on sample ', 4)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('difference is ', 76931.51, 4611804.0, 'with components', 500)\n",
      "Large CNN Error: 1.29%\n",
      "('doing self_pca on sample ', 5)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 76683.8, 4611040.0, 'with components', 500)\n",
      "Large CNN Error: 1.32%\n",
      "('doing self_pca on sample ', 6)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 74909.56, 4610224.5, 'with components', 500)\n",
      "Large CNN Error: 1.39%\n",
      "('doing self_pca on sample ', 7)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 75722.93, 4612223.5, 'with components', 500)\n",
      "Large CNN Error: 1.40%\n",
      "('doing self_pca on sample ', 8)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 74473.09, 4607388.5, 'with components', 500)\n",
      "Large CNN Error: 1.31%\n",
      "('doing self_pca on sample ', 9)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 72775.51, 4615617.0, 'with components', 500)\n",
      "Large CNN Error: 1.28%\n",
      "('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (True, 500, 1.351818182685156, 0.05394365058945604))\n",
      "('doing self_pca on sample ', 0)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6508.518, 4612887.5, 'with components', 600)\n",
      "Large CNN Error: 1.44%\n",
      "('doing self_pca on sample ', 1)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6213.42, 4609432.0, 'with components', 600)\n",
      "Large CNN Error: 1.38%\n",
      "('doing self_pca on sample ', 2)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 5674.5703, 4616055.0, 'with components', 600)\n",
      "Large CNN Error: 1.33%\n",
      "('doing self_pca on sample ', 3)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 4600.4727, 4612305.0, 'with components', 600)\n",
      "Large CNN Error: 1.27%\n",
      "('doing self_pca on sample ', 4)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 7700.0254, 4615023.0, 'with components', 600)\n",
      "Large CNN Error: 1.22%\n",
      "('doing self_pca on sample ', 5)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6124.8096, 4611006.0, 'with components', 600)\n",
      "Large CNN Error: 1.35%\n",
      "('doing self_pca on sample ', 6)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 7073.125, 4614342.0, 'with components', 600)\n",
      "Large CNN Error: 1.37%\n",
      "('doing self_pca on sample ', 7)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 5311.9077, 4611226.5, 'with components', 600)\n",
      "Large CNN Error: 1.24%\n",
      "('doing self_pca on sample ', 8)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 5933.436, 4609177.0, 'with components', 600)\n",
      "Large CNN Error: 1.44%\n",
      "('doing self_pca on sample ', 9)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6407.7163, 4615673.5, 'with components', 600)\n",
      "Large CNN Error: 1.50%\n",
      "('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (True, 600, 1.3527272735942488, 0.0869881730718261))\n",
      "('doing self_pca on sample ', 0)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 220.48491, 4607773.0, 'with components', 700)\n",
      "Large CNN Error: 1.25%\n",
      "('doing self_pca on sample ', 1)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 243.70682, 4609239.5, 'with components', 700)\n",
      "Large CNN Error: 1.36%\n",
      "('doing self_pca on sample ', 2)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 448.68353, 4613114.0, 'with components', 700)\n",
      "Large CNN Error: 1.27%\n",
      "('doing self_pca on sample ', 3)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 383.24185, 4612154.5, 'with components', 700)\n",
      "Large CNN Error: 1.29%\n",
      "('doing self_pca on sample ', 4)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 385.21143, 4615627.5, 'with components', 700)\n",
      "Large CNN Error: 1.28%\n",
      "('doing self_pca on sample ', 5)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 502.77194, 4605444.5, 'with components', 700)\n",
      "Large CNN Error: 1.42%\n",
      "('doing self_pca on sample ', 6)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 295.25195, 4612600.5, 'with components', 700)\n",
      "Large CNN Error: 1.47%\n",
      "('doing self_pca on sample ', 7)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 465.28055, 4604865.0, 'with components', 700)\n",
      "Large CNN Error: 1.31%\n",
      "('doing self_pca on sample ', 8)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 289.08948, 4614534.0, 'with components', 700)\n",
      "Large CNN Error: 1.37%\n",
      "('doing self_pca on sample ', 9)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 323.6797, 4612466.5, 'with components', 700)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large CNN Error: 1.33%\n",
      "('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (True, 700, 1.3354545463215246, 0.06747512575080133))\n",
      "('doing self_pca on sample ', 0)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6.5539985, 4609081.0, 'with components', 784)\n",
      "Large CNN Error: 1.34%\n",
      "('doing self_pca on sample ', 1)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6.4689403, 4609177.0, 'with components', 784)\n",
      "Large CNN Error: 1.35%\n",
      "('doing self_pca on sample ', 2)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6.0392194, 4613922.5, 'with components', 784)\n",
      "Large CNN Error: 1.26%\n",
      "('doing self_pca on sample ', 3)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6.605329, 4609106.5, 'with components', 784)\n",
      "Large CNN Error: 1.42%\n",
      "('doing self_pca on sample ', 4)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6.706969, 4607386.5, 'with components', 784)\n",
      "Large CNN Error: 1.16%\n",
      "('doing self_pca on sample ', 5)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6.243414, 4606981.5, 'with components', 784)\n",
      "Large CNN Error: 1.21%\n",
      "('doing self_pca on sample ', 6)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6.115932, 4613142.5, 'with components', 784)\n",
      "Large CNN Error: 1.44%\n",
      "('doing self_pca on sample ', 7)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6.381496, 4607776.0, 'with components', 784)\n",
      "Large CNN Error: 1.37%\n",
      "('doing self_pca on sample ', 8)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6.214953, 4608174.5, 'with components', 784)\n",
      "Large CNN Error: 1.20%\n",
      "('doing self_pca on sample ', 9)\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('difference is ', 6.37434, 4612056.0, 'with components', 784)\n",
      "Large CNN Error: 1.24%\n",
      "('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (True, 784, 1.2981818186153062, 0.09134441180373991))\n",
      "('The job took ', datetime.timedelta(0, 18371, 930119))\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "#model = larger_model()\n",
    "#wsave = model.get_weights()\n",
    "\n",
    "error = 100\n",
    "clean_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing clean on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "#    error = run_example(restore = None, zerofac = zfac)\n",
    "    clean_errors[i] = error\n",
    "\n",
    "pca_mean_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing pca_mean on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "#    error = run_example(restore = 'pca_mean', zerofac = zfac)\n",
    "    pca_mean_errors[i] = error\n",
    "print('the mean for pca_mean is %5.3f with standard deviation of %5.3f', \n",
    "      (np.mean(pca_mean_errors), np.std(pca_mean_errors)))\n",
    "\n",
    "    \n",
    "self_mean_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing self_mean on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "#    error = run_example(restore = 'self_mean', zerofac = zfac)\n",
    "    self_mean_errors[i] = error\n",
    "print('the mean for self_mean is %5.3f with standard deviation of %5.3f', \n",
    "      (np.mean(self_mean_errors), np.std(self_mean_errors)))\n",
    "    \n",
    "keep = True\n",
    "components = 100\n",
    "pca_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing pca on sample \",i)\n",
    "#    error = run_example(restore = 'pca', zerofac = zfac, components = components, keep = keep)\n",
    "    pca_errors[i] = error\n",
    "print('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (keep, components, np.mean(pca_errors), np.std(pca_errors)))\n",
    "\n",
    "keep = True\n",
    "iterations = 4\n",
    "components = 100\n",
    "self_pca_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing self_pca on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "#    error = run_example(restore = 'self_pca', zerofac = zfac, components = components, keep = keep, iterations=iterations)\n",
    "    self_pca_errors[i] = error\n",
    "print('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (keep, components, np.mean(self_pca_errors), np.std(self_pca_errors)))\n",
    "\n",
    "components = 100\n",
    "self_pca_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing self_pca on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "    error = run_example(restore = 'compress', zerofac = zfac, components = components, keep = keep, iterations=iterations)\n",
    "    self_pca_errors[i] = error\n",
    "print('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (keep, components, np.mean(self_pca_errors), np.std(self_pca_errors)))\n",
    "\n",
    "components = 200\n",
    "self_pca_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing self_pca on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "    error = run_example(restore = 'compress', zerofac = zfac, components = components, keep = keep, iterations=iterations)\n",
    "    self_pca_errors[i] = error\n",
    "print('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (keep, components, np.mean(self_pca_errors), np.std(self_pca_errors)))\n",
    "\n",
    "components = 300\n",
    "self_pca_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing self_pca on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "    error = run_example(restore = 'compress', zerofac = zfac, components = components, keep = keep, iterations=iterations)\n",
    "    self_pca_errors[i] = error\n",
    "print('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (keep, components, np.mean(self_pca_errors), np.std(self_pca_errors)))\n",
    "\n",
    "components = 400\n",
    "self_pca_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing self_pca on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "    error = run_example(restore = 'compress', zerofac = zfac, components = components, keep = keep, iterations=iterations)\n",
    "    self_pca_errors[i] = error\n",
    "print('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (keep, components, np.mean(self_pca_errors), np.std(self_pca_errors)))\n",
    "\n",
    "components = 500\n",
    "self_pca_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing self_pca on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "    error = run_example(restore = 'compress', zerofac = zfac, components = components, keep = keep, iterations=iterations)\n",
    "    self_pca_errors[i] = error\n",
    "print('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (keep, components, np.mean(self_pca_errors), np.std(self_pca_errors)))\n",
    "\n",
    "components = 600\n",
    "self_pca_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing self_pca on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "    error = run_example(restore = 'compress', zerofac = zfac, components = components, keep = keep, iterations=iterations)\n",
    "    self_pca_errors[i] = error\n",
    "print('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (keep, components, np.mean(self_pca_errors), np.std(self_pca_errors)))\n",
    "\n",
    "components = 700\n",
    "self_pca_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing self_pca on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "    error = run_example(restore = 'compress', zerofac = zfac, components = components, keep = keep, iterations=iterations)\n",
    "    self_pca_errors[i] = error\n",
    "print('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (keep, components, np.mean(self_pca_errors), np.std(self_pca_errors)))\n",
    "\n",
    "components = 784\n",
    "self_pca_errors = np.zeros(samples)\n",
    "for i in range(samples):\n",
    "    print(\"doing self_pca on sample \",i)\n",
    "#    model.set_weights(wsave)\n",
    "    error = run_example(restore = 'compress', zerofac = zfac, components = components, keep = keep, iterations=iterations)\n",
    "    self_pca_errors[i] = error\n",
    "print('the mean with %s and %d components is %5.3f with standard deviation of %5.3f', (keep, components, np.mean(self_pca_errors), np.std(self_pca_errors)))\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(\"The job took \", end-start)\n",
    "\n",
    "\n",
    "\"\"\" Now output the result \"\"\"\n",
    "outfile = 'Result/result'\n",
    "outfile += ('_zfac'+str(zfac))\n",
    "outfile += ('_epochs'+str(epochs))\n",
    "outfile += ('_comps'+str(components))\n",
    "outfile += ('_iters'+str(iterations))\n",
    "\n",
    "#np.savez(outfile,clean_errors,pca_mean_errors,self_mean_errors, pca_errors, self_pca_errors)\n",
    "\n",
    "initial = [[None for _ in range(samples+3)] for _ in range(6)]\n",
    "col_array = [\"\" for x in range(samples+2)]\n",
    "for col in range(samples):\n",
    "    col_array[col] = 'sample '+str(col)\n",
    "col_array[samples] = 'mean'\n",
    "col_array[samples+1] = 'standard deviation'\n",
    "    \n",
    "index_array = [\"\" for x in range(5)]\n",
    "\n",
    "index_array[0] = \"clean_errors\"\n",
    "#clean_errors = np.random.randint(10,size=samples)\n",
    "for i in range(samples):\n",
    "    initial[1][i+1] = clean_errors[i]\n",
    "initial[1][samples+1] = np.mean(clean_errors)\n",
    "initial[1][samples+2] = np.std(clean_errors)\n",
    "    \n",
    "index_array[1] = \"pca_mean_errors\"\n",
    "#pca_mean_errors = np.random.randint(10,size=samples)\n",
    "for i in range(samples):\n",
    "    initial[2][i+1] = pca_mean_errors[i]\n",
    "initial[2][samples+1] = np.mean(pca_mean_errors)\n",
    "initial[2][samples+2] = np.std(pca_mean_errors)\n",
    "    \n",
    "index_array[2] = \"self_mean_errors\"\n",
    "#self_mean_errors = np.random.randint(10,size=samples)\n",
    "for i in range(samples):\n",
    "    initial[3][i+1] = self_mean_errors[i]\n",
    "initial[3][samples+1] = np.mean(self_mean_errors)\n",
    "initial[3][samples+2] = np.std(self_mean_errors)\n",
    "\n",
    "index_array[3] = \"pca_errors\"\n",
    "#pca_errors = np.random.randint(10,size=samples)\n",
    "for i in range(samples):\n",
    "    initial[4][i+1] = pca_errors[i]\n",
    "initial[4][samples+1] = np.mean(pca_errors)\n",
    "initial[4][samples+2] = np.std(pca_errors)\n",
    "    \n",
    "index_array[4] = \"self_pca_errors\"\n",
    "#self_pca_errors = np.random.randint(10,size=samples)\n",
    "for i in range(samples):\n",
    "    initial[5][i+1] = self_pca_errors[i]\n",
    "initial[5][samples+1] = np.mean(self_pca_errors)\n",
    "initial[5][samples+2] = np.std(self_pca_errors)\n",
    "\n",
    "data3_np = np.array(initial)\n",
    "\n",
    "data3_df = pd.DataFrame(data=data3_np[1:,1:],\n",
    "                        index=np.array(index_array),\n",
    "                        columns=np.array(col_array))\n",
    "outfile += '.csv'\n",
    "\n",
    "data3_df.to_csv(outfile, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
